from fastapi import FastAPI, File, UploadFile
from pydantic import BaseModel
import uvicorn
from ultralytics import YOLO
import torch
import numpy as np
from io import BytesIO
from PIL import Image
import cv2
from fastapi.responses import FileResponse
from fastapi.responses import Response


app = FastAPI()

class AIRequest(BaseModel) :
    data : list # spring ì—ì„œ ë°›ì€ ì˜ˆì œ ë°ì´í„°

class AIResponse(BaseModel) :
    result : str # ì˜ˆì¸¡ ê²°ê³¼

@app.get("/")
async def root():
    return {"message": "Hello World"}


@app.get("/hello/{name}")
async def say_hello(name: str):
    return {"message": f"Hello {name}"}


model = YOLO("yolov8n.pt")  # ì‚¬ì „ í•™ìŠµëœ YOLOv8 ëª¨ë¸ ë¡œë“œ

@app.post("/detect")
async def detect_objects(file: UploadFile = File(...)):
    try:
        # íŒŒì¼ì„ ì½ê³  OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        contents = await file.read()
        image = Image.open(BytesIO(contents))
        img_np = np.array(image)
        print(file) # ìŠ¤í”„ë§ì—ì„œ ë°›ì€ íŒŒì¼ ì •ë³´ ì¶œë ¥

        # YOLOv8 ëª¨ë¸ë¡œ ê°ì²´ íƒì§€ ìˆ˜í–‰
        results = model(img_np)

        # ê°ì²´ íƒì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        detections_info = []
        
        for result in results:
            detections = result.boxes.data.tolist()
            print(f"ğŸ” íƒì§€ëœ ê°ì²´ ìˆ˜: {len(detections)}")

            # ê°ì²´ ì •ë³´ ì €ì¥
            for det in detections:
                x1, y1, x2, y2, conf, cls = map(int, det[:6])
                class_name = model.names[cls]  # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°

                detections_info.append({
                    "class": class_name,
                    "confidence": round(conf, 2),
                    "bbox": [x1, y1, x2, y2]
                })

                # ê°ì²´ íƒì§€ëœ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ë° í…ìŠ¤íŠ¸ ì¶”ê°€
                cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img_np, f"{class_name} {conf:.2f}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # íƒì§€ëœ ì´ë¯¸ì§€ ì‹œê°í™”
            image_with_boxes = result.plot()

            image_result = cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB)
            # ì´ë¯¸ì§€ ì €ì¥
            # cv2.imwrite(file.filename, image_result)
            
            # ì´ë¯¸ì§€ ë³€í™˜ ë° JPEG ì¸ì½”ë”©
            result_img = Image.fromarray(image_result[:, :, ::-1])
            img_io = BytesIO()
            result_img.save(img_io, format="JPEG")
            img_io.seek(0)

        return Response(content=img_io.getvalue(), media_type="image/jpeg",status_code=200)  
        # JSON í˜•íƒœë¡œ ê°ì²´ íƒì§€ ì •ë³´ ë°˜í™˜
        return {
            "message": "ê°ì²´ íƒì§€ ì™„ë£Œ",
            "detections": detections_info
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return Response(content=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}", media_type="text/plain", status_code=500)

if __name__ == "__main__":

    uvicorn.run(app, host= "127.0.0.1", port=8000)